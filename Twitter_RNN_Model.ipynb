{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5KeG5gE-l5tr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Dense, Embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data= pd.read_csv('twitter_training.csv', sep=',', names=['Tweet_ID','Entity','Sentiment','Tweet_content'])"
      ],
      "metadata": {
        "id": "SoiBhmfpm0ML"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True)  # Handle missing values\n",
        "data.drop_duplicates(inplace=True)  # Handle duplicate values\n",
        "encoder = LabelEncoder()\n",
        "data['Sentiment'] = encoder.fit_transform(data['Sentiment'])  # Encode sentiment labels\n"
      ],
      "metadata": {
        "id": "6X9TtGxBnAUs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['Tweet_content']\n",
        "y = data['Sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "9skAmDicnD38"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 1000  # Max number of words to consider as features\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "max_len = max([len(x) for x in X_train_seq])\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)"
      ],
      "metadata": {
        "id": "KvzK9eVpnhF4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 64, input_length=max_len))\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "FaCpeF4Yni4B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "h9v6VpplnnWZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_pad, y_train, epochs=10, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APC_yB1unqjS",
        "outputId": "904070ce-7eaa-49cf-825d-0c01038436b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1411/1411 [==============================] - 46s 29ms/step - loss: -33.2970 - accuracy: 0.3076 - val_loss: -68.4268 - val_accuracy: 0.3084\n",
            "Epoch 2/10\n",
            "1411/1411 [==============================] - 42s 29ms/step - loss: -85.5534 - accuracy: 0.3071 - val_loss: -124.8070 - val_accuracy: 0.3084\n",
            "Epoch 3/10\n",
            "1411/1411 [==============================] - 40s 28ms/step - loss: -147.1040 - accuracy: 0.3098 - val_loss: -184.4333 - val_accuracy: 0.3086\n",
            "Epoch 4/10\n",
            "1411/1411 [==============================] - 38s 27ms/step - loss: -203.9180 - accuracy: 0.3105 - val_loss: -243.1604 - val_accuracy: 0.3094\n",
            "Epoch 5/10\n",
            "1411/1411 [==============================] - 40s 28ms/step - loss: -260.9647 - accuracy: 0.3114 - val_loss: -302.0392 - val_accuracy: 0.3092\n",
            "Epoch 6/10\n",
            "1411/1411 [==============================] - 43s 31ms/step - loss: -317.8736 - accuracy: 0.3122 - val_loss: -360.8423 - val_accuracy: 0.3088\n",
            "Epoch 7/10\n",
            "1411/1411 [==============================] - 39s 27ms/step - loss: -374.4679 - accuracy: 0.3123 - val_loss: -419.3066 - val_accuracy: 0.3080\n",
            "Epoch 8/10\n",
            "1411/1411 [==============================] - 44s 31ms/step - loss: -431.0972 - accuracy: 0.3128 - val_loss: -478.0049 - val_accuracy: 0.3080\n",
            "Epoch 9/10\n",
            "1411/1411 [==============================] - 39s 27ms/step - loss: -487.8793 - accuracy: 0.3132 - val_loss: -537.5439 - val_accuracy: 0.3088\n",
            "Epoch 10/10\n",
            "1411/1411 [==============================] - 39s 28ms/step - loss: -544.5340 - accuracy: 0.3139 - val_loss: -590.7344 - val_accuracy: 0.3086\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f8db9713a00>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}